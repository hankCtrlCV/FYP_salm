# -------------------------------------------------------------
# Gaussian Belief Propagation â€“ Improved version for SLAM
# -------------------------------------------------------------
from __future__ import annotations

import logging
import math
from typing import Any, Dict, List, Optional, Tuple, Union
from algorithm.frontend.factor_ut import ensure_positive_definite

import numpy as np
import scipy.linalg

# â”€â”€â”€ Logging â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
_log = logging.getLogger("GaBP")

# â”€â”€â”€ Numerical constants â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
_EPS       = 1.0e-10
_DAMP_BEL  = 0.80          # belief-update damping
_DAMP_MSG  = 0.80          # message-update damping
_CLIP_SV   = 1.0e5         # singular-value clipping upper-bound
_MIN_PREC  = 1.0e-5       # minimum precision for numerical stability

# â”€â”€â”€ Helper functions â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def wrap_angle(t: Union[float, np.ndarray]) -> Union[float, np.ndarray]:
    """ Wrap angle(s) to [-Ï€, Ï€]. """
    return np.arctan2(np.sin(t), np.cos(t)) if isinstance(t, np.ndarray) \
           else math.atan2(math.sin(t), math.cos(t))

def angle_diff(a1: float, a2: float) -> float:
    """Compute angular difference a1 - a2 wrapped to [-Ï€, Ï€]."""
    return wrap_angle(a1 - a2)

def is_pd(L: np.ndarray, tol: float = 1e-10) -> bool:
    """Check if matrix is positive definite within a numerical tolerance."""
    min_eig = np.linalg.eigvalsh(L).min()
    return min_eig > -tol

def make_pd(A: np.ndarray, eps: float = 1e-8, clip_sv: float = 1e5) -> np.ndarray:
    """Ensure positive-definite by eigenvalue flooring and upper bound."""
    A = 0.5 * (A + A.T)
    try:
        w, Q = np.linalg.eigh(A)
        # å…ˆä¸Šç•Œclipï¼Œå†ä¸‹ç•Œfloor
        w_clipped = np.clip(w, -clip_sv, clip_sv)
        w_safe = np.maximum(w_clipped, eps)
        # æ£€æŸ¥æœ‰æ— ä¿®æ­£
        if np.any(w < eps):
            # print(f"[make_pd] Info: eigenvalue corrected: {w} => {w_safe}")
            pass
        return Q @ np.diag(w_safe) @ Q.T
    except Exception:
        # æ•°å€¼å¼‚å¸¸å…œåº•
        dim = A.shape[0]
        return np.eye(dim) * eps


def stable_inv(M: np.ndarray, reg: float = _MIN_PREC) -> np.ndarray:
    """Numerically stable matrix inversion with regularization."""
    M = make_pd(M, _EPS)
    # Add diagonal regularization for better conditioning
    M_reg = M + reg * np.eye(M.shape[0])
    
    try:
        # Try Cholesky first (fastest for PD matrices)
        L = np.linalg.cholesky(M_reg)
        return np.linalg.solve(L, np.linalg.solve(L.T, np.eye(M.shape[0])))
    except np.linalg.LinAlgError:
        U, s, Vt = np.linalg.svd(M_reg, full_matrices=False)
        s = np.clip(s, _MIN_PREC, _CLIP_SV)
        return Vt.T @ np.diag(1.0 / s) @ U.T
    
def info_to_gaussian(L: np.ndarray, eta: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
    """Convert information form to moment form."""
    Î£ = stable_inv(L)
    Î¼ = Î£ @ eta
    return Î¼, Î£


def _clip_pair(L: np.ndarray, eta: np.ndarray,
               s_max_lim: float = _CLIP_SV) -> Tuple[np.ndarray, np.ndarray]:
    if L.size == 0:
        return L, eta

    try:
        s_max = np.abs(np.linalg.eigvalsh(L)).max()
        if s_max <= s_max_lim:
            return L, eta

        w, Q = np.linalg.eigh(L)

        if np.abs(w).max() > s_max_lim:
            w_clipped = np.clip(w, -s_max_lim, s_max_lim)
            # å…ˆ clipï¼Œå†ç›´æ¥åš eigen-floor ä¿ PD
            w_safe = np.maximum(w_clipped, _EPS)
            L_clipped = Q @ np.diag(w_safe) @ Q.T            # å·² PD

            # Î¼ = Lâ»Â¹Î·, ç”¨åŒä¸€ (Q, w_safe)
            mu = Q @ ((Q.T @ eta) / w_safe)
            eta_new = L_clipped @ mu
            return L_clipped, eta_new
    except Exception:
        pass
    return L, eta


def safe_subtract_info(L1, eta1, L2, eta2):
    L_diff = L1 - L2
    eta_diff = eta1 - eta2

    try:
        if is_pd(L_diff, tol=1e-10):
            return L_diff, eta_diff  # Already PD
    except:
        pass

    # Project to PD
    w, Q = np.linalg.eigh(L_diff)
    w_clipped = np.maximum(w, _MIN_PREC)
    L_pd = Q @ np.diag(w_clipped) @ Q.T

    # Option 2: é‡æ–°åŒæ­¥Î·ï¼Œä¿è¯ mean ä¸å˜
    # å…ˆè®¡ç®— mean: mu = L_diff^-1 @ eta_diff
    try:
        mu_tmp = stable_inv(L_pd) @ eta_diff
        eta_consistent = L_pd @ mu_tmp
        return L_pd, eta_consistent
    except Exception as e:
        # å…œåº•ï¼šæ•°å€¼å‡ºé”™æ—¶é€€å› Option 1
        print(f"[WARN] Option 2 Î·ä¿®æ­£å¤±è´¥, fallback to Option 1: {e}")
        return L_pd, eta_diff


# â”€â”€â”€ Variable node â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class VarNode:
    def __init__(self, key: str, dim: int, mu0: np.ndarray,
                 damping: float,
                 prior_mean: Optional[np.ndarray] = None,
                 prior_sigma: Optional[Union[float, np.ndarray]] = None,
                 angle_indices: Optional[List[int]] = None):
        self.key   = key
        self.dim   = dim
        self.damp  = float(damping)
        
        # Improved angle detection
        self.angle_indices = angle_indices or []
        if not self.angle_indices:
            # Default angle detection for SLAM
            if "theta" in key.lower() or "yaw" in key.lower():
                self.angle_indices = [dim - 1]  # Assume last dimension is angle
            elif key.startswith("x") and dim >= 3:
                self.angle_indices = [2]  # SE(2) pose: [x, y, theta]
        
        # Setup prior
        if prior_mean is None or prior_sigma is None:
            # Weak prior
            L0 = np.eye(dim) * _MIN_PREC
            eta0 = L0 @ mu0
        else:
            if np.isscalar(prior_sigma):
                L0 = np.eye(dim) / (prior_sigma**2 + _EPS)
            else:
                sigma_arr = np.array(prior_sigma)
                L0 = np.diag(1.0 / (sigma_arr**2 + _EPS))
            eta0 = L0 @ prior_mean
        
        L0 = make_pd(L0)
        self.L_prior, self.eta_prior = L0, eta0
        self.L, self.eta             = L0.copy(), eta0.copy()
        
        # Initialize mean
        self.mu, _ = info_to_gaussian(self.L, self.eta)
        self._wrap_angles()
        
        self.mu_prev = self.mu.copy()
        self.history = [self.mu.copy()]
        self.fids: List[int] = []

    def _wrap_angles(self):
        """Wrap angle components to [-Ï€, Ï€]."""
        for idx in self.angle_indices:
            if 0 <= idx < self.dim:
                self.mu[idx] = wrap_angle(self.mu[idx])

    def belief(self) -> Tuple[np.ndarray, np.ndarray]:
        return self.L.copy(), self.eta.copy()
    
    def mean(self) -> np.ndarray:
        return self.mu.copy()

    def update(self, L_new: np.ndarray, eta_new: np.ndarray) -> float:
        """Update belief with damping and proper angle handling."""
        # Damped update
        L_damped = self.damp * L_new + (1 - self.damp) * self.L
        eta_damped = self.damp * eta_new + (1 - self.damp) * self.eta
        
        # Ensure PD
        L_damped = make_pd(L_damped)
        
        # Compute new mean
        mu_new, _ = info_to_gaussian(L_damped, eta_damped)
        
        # Handle angle updates properly - ä¿®æ­£ç‰ˆæœ¬
        if self.angle_indices:
            for idx in self.angle_indices:
                if 0 <= idx < self.dim:
                    # è®¡ç®—æœ€çŸ­è§’åº¦è·¯å¾„æ›´æ–°
                    raw_diff = mu_new[idx] - self.mu[idx]
                    wrapped_diff = wrap_angle(raw_diff)
                    mu_new[idx] = wrap_angle(self.mu[idx] + wrapped_diff)
            
            # ğŸ”¥ å…³é”®ä¿®å¤ï¼šè§’åº¦wrapåé‡æ–°åŒæ­¥Î·
            eta_damped = L_damped @ mu_new
        
        # Compute convergence metric
        delta = float(np.linalg.norm(mu_new - self.mu))
        
        # Update state
        self.mu_prev = self.mu.copy()
        self.mu = mu_new
        self.L = L_damped
        self.eta = eta_damped  # ç°åœ¨Î·ä¸wrapped Î¼ä¿æŒä¸€è‡´
        self.history.append(self.mu.copy())
        
        return delta

# â”€â”€â”€ Factor node â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class FacNode:
    def __init__(self, fid: int, factor: Any, mu: Dict[str, np.ndarray], cov: Dict[str, np.ndarray]):
        self.id   = fid
        self.fact = factor

        # å…³é”®ï¼šç›´æ¥ç”¨å½“å‰mu/covè°ƒç”¨linearizeè·å–æ‰€æœ‰æ¶‰åŠå˜é‡çš„key
        blocks = factor.linearize(mu, cov)
        # åªä¿ç•™strç±»å‹keyï¼Œå³æ‰€æœ‰å•å˜é‡ç›¸å…³ï¼ˆæ”¯æŒtupleå¯æ‰©å±•ï¼‰
        self.vars = [k for k in blocks if isinstance(k, str)]
        self.prev_msg = {k: (np.zeros((factor._get_dim(k), factor._get_dim(k))),
                             np.zeros(factor._get_dim(k))) for k in self.vars}
        self.robot_set = {
            int(v.split('_')[0][1:]) for v in self.vars if v.startswith('x')
        }
        # print(f"Adapter type: {type(self.fact)}, raw type: {type(self.fact._f)}")


    def reset(self):
        for k in self.vars:
            dim = self.fact._get_dim(k)
            self.prev_msg[k] = (np.zeros((dim, dim)), np.zeros(dim))


def _extract_block_tuple(block, dim):
    if isinstance(block, tuple) and len(block) == 2:
        return block
    elif isinstance(block, np.ndarray):
        print(f"[WARN] Factor block åªè¿”å›çŸ©é˜µï¼Œæ— eta: {block.shape}")
        return block, np.zeros(dim)
    else:
        print(f"[WARN] Factor block ç±»å‹å¼‚å¸¸: {type(block)}, å†…å®¹: {block}")
        return np.zeros((dim, dim)), np.zeros(dim)


# â”€â”€â”€ GBP graph â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class GBPGraph:
    def __init__(self, factors: List[Any], variables: Dict[str, np.ndarray],
                 priors: Optional[Dict[str, Tuple[np.ndarray, np.ndarray]]] = None,
                 angle_vars: Optional[Dict[str, List[int]]] = None,
                 bel_damp: float = _DAMP_BEL, msg_damp: float = _DAMP_MSG):

        self.d_bel, self.d_msg = float(bel_damp), float(msg_damp)
        self.v: Dict[str, VarNode] = {}
        for k, Î¼0 in variables.items():
            pm, ps = priors.get(k, (None, None)) if priors else (None, None)
            angle_idx = angle_vars.get(k) if angle_vars else None
            self.v[k] = VarNode(k, Î¼0.size, Î¼0, self.d_bel, pm, ps, angle_idx)

        # -- Patch here: FacNodeæ­£ç¡®æ”¶é›†å˜é‡ --
        self.f: List[FacNode] = []
        mu_init = {k: v.mean() for k, v in self.v.items()}
        cov_init = {k: np.eye(v.dim)*0.01 for k, v in self.v.items()}
        for fid, fac in enumerate(factors):
            fn = FacNode(fid, fac, mu_init, cov_init)
            if fn.vars:
                self.f.append(fn)
                for k in fn.vars:
                    self.v[k].fids.append(fid)
        
        # Message storage
        self.m_v2f: Dict[Tuple[str, int], Tuple[np.ndarray, np.ndarray]] = {}
        self.m_f2v: Dict[Tuple[int, str], Tuple[np.ndarray, np.ndarray]] = {}
        self.max_delta_history: List[float] = []
        
        #communication statistics
        self.comm_bytes = 0
        self.robot_vars = self._identify_robot_variables()

    def _identify_robot_variables(self) -> Dict[str, int]:
        """è¯†åˆ«æ¯ä¸ªå˜é‡å±äºå“ªä¸ªæœºå™¨äºº"""
        robot_vars = {}
        for var_name in self.v:
            robot_id = self._get_robot_id(var_name)
            if robot_id is not None:
                robot_vars[var_name] = robot_id
        return robot_vars

    def _get_robot_id(self, var_name: str) -> Optional[int]:
        """ä»å˜é‡åæå–æœºå™¨äººID - æ›´é²æ£’çš„ç‰ˆæœ¬"""
        # æ”¯æŒå¤šç§å‘½åçº¦å®š
        patterns = [
            r'^x(\d+)_',    # x0_1, x1_2 ç­‰
            r'^robot(\d+)_', # robot0_pose ç­‰
            r'^r(\d+)_',    # r0_1 ç­‰
        ]
        
        import re
        for pattern in patterns:
            match = re.match(pattern, var_name)
            if match:
                try:
                    return int(match.group(1))
                except ValueError:
                    continue
        return None

    
    def _is_cross_robot(self, var_name: str, fn: FacNode) -> bool:
        if var_name not in self.robot_vars:           # å˜é‡æœªå½’å±ä»»ä½•æœºå™¨äºº
            return False
        return self.robot_vars[var_name] not in fn.robot_set
    
    def _sweep(self) -> float:
        """One complete GBP iteration."""
        
        # 1) Variable to Factor messages
        for k, vn in self.v.items():
            L_belief, eta_belief = vn.belief()
            
            for fid in vn.fids:
                fn_obj = self.f[fid]
                # Get previous Fâ†’V message
                L_f2v, eta_f2v = self.m_f2v.get((fid, k), 
                                                (np.zeros((vn.dim, vn.dim)),
                                                 np.zeros(vn.dim)))
                
                # Compute Vâ†’F message (belief minus incoming)
                L_msg, eta_msg = safe_subtract_info(L_belief, eta_belief, 
                                                   L_f2v, eta_f2v)
                
                # Damping
                L_prev, eta_prev = self.m_v2f.get((k, fid),
                                                 (np.zeros_like(L_msg), 
                                                  np.zeros_like(eta_msg)))
                L_msg = self.d_msg * L_msg + (1 - self.d_msg) * L_prev
                eta_msg = self.d_msg * eta_msg + (1 - self.d_msg) * eta_prev
                
                # Clip for numerical stability
                L_msg, eta_msg = _clip_pair(L_msg, eta_msg)
                
                self.m_v2f[(k, fid)] = (L_msg, eta_msg)
                
                if self._is_cross_robot(k, fn_obj): 
                    # å¯¹ç§°ä¿¡æ¯çŸ©é˜µåªéœ€ä¼ é€’ä¸Š/ä¸‹ä¸‰è§’+ä¿¡æ¯å‘é‡
                    # æ¯ä¸ªæµ®ç‚¹æ•°8å­—èŠ‚
                    matrix_elements = vn.dim * (vn.dim + 1) // 2  # ä¸Šä¸‰è§’å…ƒç´ æ•°é‡
                    vector_elements = vn.dim                      # å‘é‡å…ƒç´ æ•°é‡
                    self.comm_bytes += 8 * (matrix_elements + vector_elements)

        # 2) Factor to Variable messages  
        for fn in self.f:
            # Collect current estimates
            Î¼_dict, Î£_dict = {}, {}
            for k in fn.vars:
                Î¼_dict[k] = self.v[k].mean()
                # Wrap angles for linearization
                for idx in self.v[k].angle_indices:
                    if 0 <= idx < len(Î¼_dict[k]):
                        Î¼_dict[k][idx] = wrap_angle(Î¼_dict[k][idx])
                
                _, Î£ = info_to_gaussian(*self.v[k].belief())
                # Add small regularization for numerical stability
                Î£_dict[k] = make_pd(Î£, _MIN_PREC)

            # Linearize factor
            try:
                blocks = fn.fact.linearize(Î¼_dict, Î£_dict)
            except Exception as e:
                _log.error(f"Factor {fn.id} linearization failed: {e}")
                continue

            # Compute messages for each connected variable
            for tgt in fn.vars:
                vn = self.v[tgt]
                dim = vn.dim

                # ---- PATCH: å®‰å…¨è§£åŒ…å¯¹è§’å— ----
                Lkk, Î·k = _extract_block_tuple(blocks.get(tgt, None), dim)
                Lkk = make_pd(Lkk, _MIN_PREC)

                
                # Schur complement for other variables
                for oth in fn.vars:
                    if oth == tgt:
                        continue
                    
                    Lkj = None
                    if (tgt, oth) in blocks:
                        Lkj = blocks[(tgt, oth)]
                    elif (oth, tgt) in blocks:
                        Lkj = blocks[(oth, tgt)].T
                    if Lkj is None or not isinstance(Lkj, np.ndarray):
                        continue
                                
                    # Get other variable's message and block
                    Lj_msg, Î·j_msg = self.m_v2f.get((oth, fn.id),
                                                   (np.zeros((self.v[oth].dim,
                                                            self.v[oth].dim)),
                                                    np.zeros(self.v[oth].dim)))
                    
                    Ljj, Î·j = blocks.get(oth, (np.zeros((self.v[oth].dim,
                                                        self.v[oth].dim)),
                                              np.zeros(self.v[oth].dim)))
                    
                    # Compute Schur complement
                    Ljj_total = make_pd(Ljj + Lj_msg, _MIN_PREC)
                    Î·j_total = Î·j + Î·j_msg
                    
                    try:
                        Ljj_inv = stable_inv(Ljj_total)
                        # Update target blocks
                        # è®¡ç®—Schur complementé¡¹
                        schur_term = Lkj @ Ljj_inv @ Lkj.T
                        schur_eta = Lkj @ Ljj_inv @ Î·j_total
                        
                       # â€”â€” ç»Ÿä¸€ç”¨ safe_subtract_info åš â€œä¿¡æ¯å‡æ³• + æŠ•å½±â€ â€”â€”
                        Lkk, Î·k = safe_subtract_info(Lkk, Î·k, schur_term, schur_eta)

                    except Exception as e:
                        _log.warning(f"Schur complement failed for factor {fn.id}: {e}")
                        pass
                
                # Damping
                L_prev, Î·_prev = self.m_f2v.get((fn.id, tgt),
                                               (np.zeros_like(Lkk), np.zeros_like(Î·k)))
                Lkk = self.d_msg * Lkk + (1 - self.d_msg) * L_prev
                Î·k = self.d_msg * Î·k + (1 - self.d_msg) * Î·_prev
                
                # Clip and store
                Lkk, Î·k = _clip_pair(Lkk, Î·k)
                self.m_f2v[(fn.id, tgt)] = (Lkk, Î·k)
                
                if self._is_cross_robot(tgt, fn): 
                    dim = self.v[tgt].dim
                    matrix_elements = dim * (dim + 1) // 2
                    vector_elements = dim
                    self.comm_bytes += 8 * (matrix_elements + vector_elements)

        # 3) Belief updates
        max_delta = 0.0
        for k, vn in self.v.items():
            # Combine prior with all incoming messages
            L_new = vn.L_prior.copy()
            eta_new = vn.eta_prior.copy()
            
            for fid in vn.fids:
                L_msg, eta_msg = self.m_f2v.get((fid, k), 
                                               (np.zeros((vn.dim, vn.dim)),
                                                np.zeros(vn.dim)))
                L_new += L_msg
                eta_new += eta_msg
            
            # Small regularization for numerical stability
            L_new = make_pd(L_new, _MIN_PREC)
            
            # Update and track convergence
            delta = vn.update(L_new, eta_new)
            max_delta = max(max_delta, delta)
        
        self.max_delta_history.append(max_delta)
        return max_delta

    def run(self, max_iter: int = 100, tol: float = 1e-5, 
            verbose: bool = True) -> Tuple[List[float], Dict[str, Any]]:
            
        """Run GBP until convergence."""
        
        # Reset state
        self.m_v2f.clear()
        self.m_f2v.clear()
        for fn in self.f:
            fn.reset()
        self.max_delta_history.clear()
        
        comm_bytes_this_run = 0
        
        if verbose:
            _log.info(f"Starting GBP with {len(self.v)} variables, {len(self.f)} factors")
        
        prev_delta = float('inf')
        for iteration in range(max_iter):
            old_comm = self.comm_bytes
            delta = self._sweep()
            comm_bytes_this_run += (self.comm_bytes - old_comm)
            
            if verbose and (iteration % 10 == 0 or delta < tol):
                _log.info(f"Iter {iteration:3d} | max Î” = {delta:.2e}")
                
            # â”€â”€ â‘¢-A è‡ªé€‚åº”é˜»å°¼ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            # ç›®æ ‡ï¼šå¦‚æœéœ‡è¡ / å‘æ•£â‡’å‡å° dampingï¼›å¿«é€Ÿæ”¶æ•›â‡’é€‚åº¦å¢å¤§
            if delta > prev_delta * 1.2:       # æ˜æ˜¾åå¼¹
                self.d_msg *= 0.5
                self.d_bel *= 0.5
            elif delta < prev_delta * 0.5:     # æ”¶æ•›é€Ÿåº¦å¾ˆå¿«
                self.d_msg = min(self.d_msg * 1.1, 0.8)
                self.d_bel = min(self.d_bel * 1.1, 0.8)
            prev_delta = delta
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            
            # Check for numerical issues
            if not np.isfinite(delta) or delta > 1e8:
                _log.error(f"Numerical instability detected at iteration {iteration}")
                break
            
            # Check convergence
            if delta < tol:
                if verbose:
                    _log.info(f"Converged at iteration {iteration} (Î” = {delta:.2e})")
                break
        else:
            if verbose:
                _log.warning(f"Reached max iterations ({max_iter}) without full convergence")
        
        stats = {
            "iterations": len(self.max_delta_history),
            "converged": len(self.max_delta_history) > 0 and self.max_delta_history[-1] < tol,
            "comm_bytes": comm_bytes_this_run,  # åªæŠ¥å‘Šæœ¬æ¬¡è¿è¡Œçš„é€šä¿¡é‡
            "total_comm_bytes": self.comm_bytes,  # æ€»ç´¯ç§¯é€šä¿¡é‡
            "final_delta": self.max_delta_history[-1] if self.max_delta_history else float('inf')
        }
        return self.max_delta_history, stats
    
    # Backward compatibility alias
    def solve(self, *args, **kwargs):
        """Backward compatibility alias for run()."""
        return self.run(*args, **kwargs)

    # â”€â”€â”€ Utility methods â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def get_means(self) -> Dict[str, np.ndarray]:
        """Get current mean estimates for all variables."""
        return {k: vn.mean() for k, vn in self.v.items()}

    def get_marginals(self) -> Dict[str, Tuple[np.ndarray, np.ndarray]]:
        """Get marginal distributions (mean, covariance) for all variables."""
        return {k: info_to_gaussian(*vn.belief()) for k, vn in self.v.items()}
    
    def get_covariances(self) -> Dict[str, np.ndarray]:
        """Get covariance matrices for all variables."""
        return {k: info_to_gaussian(*vn.belief())[1] for k, vn in self.v.items()}
    
    def get_information_matrices(self) -> Dict[str, Tuple[np.ndarray, np.ndarray]]:
        """Get information form (precision matrix, information vector) for all variables."""
        return {k: vn.belief() for k, vn in self.v.items()}
    
    def set_prior(self, var_key: str, mean: np.ndarray, 
                  sigma: Union[float, np.ndarray]):
        """Update prior for a specific variable."""
        if var_key not in self.v:
            raise ValueError(f"Variable {var_key} not found")
        
        vn = self.v[var_key]
        if np.isscalar(sigma):
            L_prior = np.eye(vn.dim) / (sigma**2 + _EPS)
        else:
            sigma_arr = np.array(sigma)
            L_prior = np.diag(1.0 / (sigma_arr**2 + _EPS))
        
        eta_prior = L_prior @ mean
        vn.L_prior = make_pd(L_prior)
        vn.eta_prior = eta_prior
    
    def reset_messages(self):
        """Reset all messages (useful for re-running optimization)."""
        self.m_v2f.clear()
        self.m_f2v.clear()
        for fn in self.f:
            fn.reset()
        # ğŸ”¥ ä¿®å¤ï¼šåŒæ­¥é‡ç½®é€šä¿¡ç»Ÿè®¡
        self.comm_bytes = 0
    
    def get_variable_history(self, var_key: str) -> List[np.ndarray]:
        """Get optimization history for a specific variable."""
        if var_key not in self.v:
            raise ValueError(f"Variable {var_key} not found")
        return self.v[var_key].history.copy()
    
    def get_convergence_history(self) -> List[float]:
        """Get convergence history (max delta per iteration)."""
        return self.max_delta_history.copy()
    
    def get_comm_bytes(self) -> int:
        """è·å–ç´¯è®¡é€šä¿¡å­—èŠ‚æ•°"""
        return self.comm_bytes

    def reset_comm_stats(self):
        """é‡ç½®é€šä¿¡ç»Ÿè®¡"""
        self.comm_bytes = 0